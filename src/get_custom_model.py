from modelfile_handler import create_and_move_modelfile, update_system_text, update_tempurature
from request_handler import generate_text,create_model

def get_custom_model(base_model_name = "dolphin-mistral"):
    """
    Creates a custom model based on a base model name and a topic from user input.
    The system prompt is generated by prompting the base model with the topic and then the user is asked if it is satisfactory.
    If not, the user is prompted again until a satisfactory system prompt is generated.
    
    Args:
        base_model_name (str): The base model to use for prompting and building off of.
        
    Returns:
        The new model name in full, in the way ollama would list it.
    """
    # Get topic from user
    while True:
        topic = input(" \n \nEnter a topic for your custom model (e.g., 'Mario', 'Shakespeare', etc.): ").strip()
        if topic:  # Check if topic is not empty
            break
        print("Topic cannot be empty. Please try again.")

    system_prompt = ""
    while True:
        text = prompt_model(base_model_name, topic)
        satis = input( "\n \n \nIs this satifactory as a system prompt? selecting no will reprompt the model. \ny for yes, n for no: " ).strip()
        if satis == 'y':  # Check if yes
            system_prompt = text
            break

    temperature = .8
    while True:
        temp_input = input("""\nWhat would you like the temperature to be? 
Please enter a number (default is 0.8): """).strip()

        if not temp_input: # If empty, use default
            break
        try:
            # Convert input to float
            new_temperature = float(temp_input)
            temperature = new_temperature
            break  
        except ValueError:
            break
    
    #create and moves modelfile to custom folders, updates system text and temperature
    modelfile_path = create_and_move_modelfile(base_model_name, topic)
    update_system_text(modelfile_path, system_prompt)
    update_tempurature(modelfile_path, temperature)

    #create the model
    custom_model_name = f"{topic}-{base_model_name}"
    model_name = create_model(custom_model_name, modelfile_path)
    full_model_name = custom_model_name + ":latest"
    print('full model name: ', full_model_name)
    return full_model_name


def prompt_model(base_model_name, topic):
    print(f" \ntopic: {topic} \n\nprompting model {base_model_name} with topic {topic} to generate a system prompt")

    text = generate_text(f"{base_model_name}", f"you are {topic}, talk like an assistant knowldgeable about {topic} in 20 words or less")

    print("\n model response: \n \n -------------------------------------------------------------------------- \n", text, "\n --------------------------------------------------------------------------")

    return text

get_custom_model()


